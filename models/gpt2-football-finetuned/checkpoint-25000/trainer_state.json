{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 2.0621996741529007,
  "eval_steps": 500,
  "global_step": 25000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.04124646827115428,
      "grad_norm": 3.0805039405822754,
      "learning_rate": 4.9313976188512194e-05,
      "loss": 0.3731,
      "step": 500
    },
    {
      "epoch": 0.08249293654230856,
      "grad_norm": 1.8823235034942627,
      "learning_rate": 4.862657757980698e-05,
      "loss": 0.2456,
      "step": 1000
    },
    {
      "epoch": 0.12373940481346285,
      "grad_norm": 1.9177714586257935,
      "learning_rate": 4.793917897110177e-05,
      "loss": 0.2336,
      "step": 1500
    },
    {
      "epoch": 0.16498587308461712,
      "grad_norm": 1.3547335863113403,
      "learning_rate": 4.725178036239655e-05,
      "loss": 0.2273,
      "step": 2000
    },
    {
      "epoch": 0.20623234135577143,
      "grad_norm": 1.1950922012329102,
      "learning_rate": 4.656438175369133e-05,
      "loss": 0.2187,
      "step": 2500
    },
    {
      "epoch": 0.2474788096269257,
      "grad_norm": 1.1492396593093872,
      "learning_rate": 4.5876983144986116e-05,
      "loss": 0.2177,
      "step": 3000
    },
    {
      "epoch": 0.28872527789808,
      "grad_norm": 0.9531201720237732,
      "learning_rate": 4.51895845362809e-05,
      "loss": 0.2149,
      "step": 3500
    },
    {
      "epoch": 0.32997174616923425,
      "grad_norm": 1.03315007686615,
      "learning_rate": 4.4502185927575685e-05,
      "loss": 0.2145,
      "step": 4000
    },
    {
      "epoch": 0.37121821444038855,
      "grad_norm": 0.8782081604003906,
      "learning_rate": 4.381478731887047e-05,
      "loss": 0.2098,
      "step": 4500
    },
    {
      "epoch": 0.41246468271154285,
      "grad_norm": 0.9562194347381592,
      "learning_rate": 4.312738871016525e-05,
      "loss": 0.2097,
      "step": 5000
    },
    {
      "epoch": 0.4537111509826971,
      "grad_norm": 0.7818219065666199,
      "learning_rate": 4.243999010146004e-05,
      "loss": 0.2115,
      "step": 5500
    },
    {
      "epoch": 0.4949576192538514,
      "grad_norm": 0.8277163505554199,
      "learning_rate": 4.175259149275482e-05,
      "loss": 0.2071,
      "step": 6000
    },
    {
      "epoch": 0.5362040875250057,
      "grad_norm": 0.7172802090644836,
      "learning_rate": 4.10651928840496e-05,
      "loss": 0.2068,
      "step": 6500
    },
    {
      "epoch": 0.57745055579616,
      "grad_norm": 0.7477802038192749,
      "learning_rate": 4.0377794275344385e-05,
      "loss": 0.2071,
      "step": 7000
    },
    {
      "epoch": 0.6186970240673142,
      "grad_norm": 0.6020976901054382,
      "learning_rate": 3.969039566663918e-05,
      "loss": 0.207,
      "step": 7500
    },
    {
      "epoch": 0.6599434923384685,
      "grad_norm": 0.705047070980072,
      "learning_rate": 3.9002997057933954e-05,
      "loss": 0.2055,
      "step": 8000
    },
    {
      "epoch": 0.7011899606096228,
      "grad_norm": 0.7181963920593262,
      "learning_rate": 3.831559844922874e-05,
      "loss": 0.2033,
      "step": 8500
    },
    {
      "epoch": 0.7424364288807771,
      "grad_norm": 0.7865104079246521,
      "learning_rate": 3.762819984052352e-05,
      "loss": 0.2067,
      "step": 9000
    },
    {
      "epoch": 0.7836828971519314,
      "grad_norm": 0.6144213080406189,
      "learning_rate": 3.694080123181831e-05,
      "loss": 0.2041,
      "step": 9500
    },
    {
      "epoch": 0.8249293654230857,
      "grad_norm": 0.7011426687240601,
      "learning_rate": 3.625340262311309e-05,
      "loss": 0.202,
      "step": 10000
    },
    {
      "epoch": 0.8661758336942399,
      "grad_norm": 0.7059629559516907,
      "learning_rate": 3.556600401440788e-05,
      "loss": 0.2003,
      "step": 10500
    },
    {
      "epoch": 0.9074223019653942,
      "grad_norm": 0.605380117893219,
      "learning_rate": 3.4878605405702655e-05,
      "loss": 0.2011,
      "step": 11000
    },
    {
      "epoch": 0.9486687702365485,
      "grad_norm": 0.5510129332542419,
      "learning_rate": 3.4191206796997446e-05,
      "loss": 0.2039,
      "step": 11500
    },
    {
      "epoch": 0.9899152385077028,
      "grad_norm": 0.7404103875160217,
      "learning_rate": 3.350380818829223e-05,
      "loss": 0.2012,
      "step": 12000
    },
    {
      "epoch": 1.0310998370764504,
      "grad_norm": 0.7833455801010132,
      "learning_rate": 3.2816409579587015e-05,
      "loss": 0.1924,
      "step": 12500
    },
    {
      "epoch": 1.0723463053476046,
      "grad_norm": 0.5333886742591858,
      "learning_rate": 3.212901097088179e-05,
      "loss": 0.1883,
      "step": 13000
    },
    {
      "epoch": 1.113592773618759,
      "grad_norm": 0.5346872806549072,
      "learning_rate": 3.1441612362176584e-05,
      "loss": 0.1897,
      "step": 13500
    },
    {
      "epoch": 1.1548392418899132,
      "grad_norm": 0.6582801938056946,
      "learning_rate": 3.075421375347137e-05,
      "loss": 0.1878,
      "step": 14000
    },
    {
      "epoch": 1.1960857101610674,
      "grad_norm": 0.6142246723175049,
      "learning_rate": 3.0066815144766146e-05,
      "loss": 0.1907,
      "step": 14500
    },
    {
      "epoch": 1.2373321784322218,
      "grad_norm": 0.5318297743797302,
      "learning_rate": 2.9379416536060934e-05,
      "loss": 0.1896,
      "step": 15000
    },
    {
      "epoch": 1.278578646703376,
      "grad_norm": 0.609053909778595,
      "learning_rate": 2.869201792735572e-05,
      "loss": 0.1883,
      "step": 15500
    },
    {
      "epoch": 1.3198251149745304,
      "grad_norm": 0.6204573512077332,
      "learning_rate": 2.80046193186505e-05,
      "loss": 0.1868,
      "step": 16000
    },
    {
      "epoch": 1.3610715832456846,
      "grad_norm": 0.7220818400382996,
      "learning_rate": 2.7317220709945284e-05,
      "loss": 0.1873,
      "step": 16500
    },
    {
      "epoch": 1.402318051516839,
      "grad_norm": 0.6051014065742493,
      "learning_rate": 2.6629822101240072e-05,
      "loss": 0.1867,
      "step": 17000
    },
    {
      "epoch": 1.4435645197879932,
      "grad_norm": 0.6064845323562622,
      "learning_rate": 2.594242349253485e-05,
      "loss": 0.1875,
      "step": 17500
    },
    {
      "epoch": 1.4848109880591474,
      "grad_norm": 0.5759933590888977,
      "learning_rate": 2.5255024883829638e-05,
      "loss": 0.1906,
      "step": 18000
    },
    {
      "epoch": 1.5260574563303018,
      "grad_norm": 0.626683235168457,
      "learning_rate": 2.456762627512442e-05,
      "loss": 0.1879,
      "step": 18500
    },
    {
      "epoch": 1.567303924601456,
      "grad_norm": 0.6010903120040894,
      "learning_rate": 2.3880227666419207e-05,
      "loss": 0.1861,
      "step": 19000
    },
    {
      "epoch": 1.6085503928726101,
      "grad_norm": 0.5872513055801392,
      "learning_rate": 2.3192829057713988e-05,
      "loss": 0.19,
      "step": 19500
    },
    {
      "epoch": 1.6497968611437646,
      "grad_norm": 0.5317152738571167,
      "learning_rate": 2.2505430449008772e-05,
      "loss": 0.1893,
      "step": 20000
    },
    {
      "epoch": 1.691043329414919,
      "grad_norm": 0.6203333735466003,
      "learning_rate": 2.1818031840303557e-05,
      "loss": 0.1869,
      "step": 20500
    },
    {
      "epoch": 1.7322897976860732,
      "grad_norm": 0.547929048538208,
      "learning_rate": 2.113063323159834e-05,
      "loss": 0.1869,
      "step": 21000
    },
    {
      "epoch": 1.7735362659572274,
      "grad_norm": 0.47824835777282715,
      "learning_rate": 2.0443234622893122e-05,
      "loss": 0.1851,
      "step": 21500
    },
    {
      "epoch": 1.8147827342283818,
      "grad_norm": 0.478270024061203,
      "learning_rate": 1.975583601418791e-05,
      "loss": 0.1872,
      "step": 22000
    },
    {
      "epoch": 1.856029202499536,
      "grad_norm": 0.5857809782028198,
      "learning_rate": 1.906843740548269e-05,
      "loss": 0.1868,
      "step": 22500
    },
    {
      "epoch": 1.8972756707706901,
      "grad_norm": 0.6174466013908386,
      "learning_rate": 1.8381038796777476e-05,
      "loss": 0.1876,
      "step": 23000
    },
    {
      "epoch": 1.9385221390418446,
      "grad_norm": 0.5440501570701599,
      "learning_rate": 1.769364018807226e-05,
      "loss": 0.1861,
      "step": 23500
    },
    {
      "epoch": 1.979768607312999,
      "grad_norm": 0.5420381426811218,
      "learning_rate": 1.7006241579367045e-05,
      "loss": 0.1838,
      "step": 24000
    },
    {
      "epoch": 2.0209532058817463,
      "grad_norm": 0.5867671966552734,
      "learning_rate": 1.631884297066183e-05,
      "loss": 0.1764,
      "step": 24500
    },
    {
      "epoch": 2.0621996741529007,
      "grad_norm": 0.5394983291625977,
      "learning_rate": 1.5631444361956614e-05,
      "loss": 0.175,
      "step": 25000
    }
  ],
  "logging_steps": 500,
  "max_steps": 36369,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 5000,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 2.321612431215821e+16,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
